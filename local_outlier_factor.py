# -*- coding: utf-8 -*-
"""Local_outlier_factor

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Im6rFOCn4fkDoZhHwboQ-tzf9DfJaqWg
"""

import pandas as pd                           #importing libraries
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive
import math
from collections import Counter

drive.mount('/content/drive', force_remount = True)          # mouting to my drive
iris_directory = '/content/drive/MyDrive/irisData/iris.data' # storing the file directory in iris_dictionary

dataset = pd.read_csv(iris_directory, header= None)
print(type(dataset))                # now reading the dataset from the directory
column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']
dataset.columns = column_names

# data pre-processing to remove/handle missing/null/duplicate values if any

    dataset.dropna()  # remove all the missing values and return the new series

    #check for null values

    if dataset.isnull().values.any():
        print("The dataset contains null values.")
    else:
        print("The dataset does not contain null values.")

    #check for duplicates

    dataset.drop_duplicates()

    if dataset.duplicated().any():
          print("The dataset contains duplicate values.")
    else:
        print("The dataset does not contain duplicate values.")

    # data visualization

    # print the whole file
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    print(dataset)

    # print max number of rows and columns
    # num_rows = dataset.shape[0]
    # num_columns = dataset.shape[1]

    # print("Number of rows:", num_rows)
    # print("Number of columns:", num_columns)

# Separate the data based on labels
setosa_data = dataset[dataset['class'] == 'Iris-setosa']
versicolor_data = dataset[dataset['class'] == 'Iris-versicolor']
virginica_data = dataset[dataset['class'] == 'Iris-virginica']

# Plot the data
plt.scatter(setosa_data['sepal_length'], setosa_data['sepal_width'], c='red', label='Iris-setosa')
plt.scatter(versicolor_data['sepal_length'], versicolor_data['sepal_width'], c='green', label='Iris-versicolor')
plt.scatter(virginica_data['sepal_length'], virginica_data['sepal_width'], c='blue', label='Iris-virginica')

# Set the labels and title
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.title('Iris Dataset')

# Show the legend
plt.legend()

# Show the plot
plt.show()

test_size = int(len(dataset) * 0.2)

# Split the dataset into training and testing sets
train_data = dataset[test_size:]
test_data = dataset[:test_size]

# print("training sets")
# print(train_data)

# print("testing sets")
# print(test_data)


# extracting features and labels for both test and train dataset
X_train = train_data.iloc[:, :-1].values
y_train = train_data.iloc[:, -1].values
X_test = test_data.iloc[:, :-1].values
y_test = test_data.iloc[:, -1].values

# print(type(X_train))
# print(type(y_train))
# print(type(X_test))
# print(type(X_test))

# print("training sets")
# print("FEATURES")
# print(X_train)
# print("-------------------------------------------------")
# print("LABELS")
# print(y_train)
# print("-------------------------------------------------")

# print("testing sets")
# print("FEATURES")
# print(X_test)
# print("-------------------------------------------------")
# print("LABELS")
# print(y_test)

# Euclidean Distance function
def Euclidean_Distance(point1, point2):
    squared_diff = 0
    for i in range(len(point1)):
        squared_diff += (point1[i] - point2[i]) ** 2
    distance = math.sqrt(squared_diff)
    return distance

def KNN_recursive(original_point,X_train,y_train, X_test,k):
  # print(distance[0])
  # print(distance[1])
  # print(distance)
  # print(type(distance))
  # print("''''''''''''")

  knn_neighbors = []
  # print(original_point[1])
  for i in range(len(X_train)):
    dis =  Euclidean_Distance(original_point[1],X_train[i])
    knn_neighbors.append((dis,y_train[i]))

  knn_neighbors = tuple(sorted(knn_neighbors))
  knn_neighbors = knn_neighbors[0:k]
  print("knn neighbors: ",knn_neighbors)
  knn_neighbors = knn_neighbors[k-1]
  # print(knn_neighbors)
  # print ("returning")
  # print("type" ,type(knn_neighbors))
  return knn_neighbors

def calculate_RD(knn_neighborhood,distanceFromTP):
  return max(knn_neighborhood,distanceFromTP)

def calculate_LRD_for_neighbors(thirdk_dis, RDforneighbor,k):
  # print(thirdk_dis,RDforneighbor)
  return 1/((thirdk_dis+RDforneighbor)/k)

def calculate_LRD_for_TP(RDs,k):
  RDs_sum= 0

  for i in range(k):
    RDs_sum+=RDs[i]

  return 1/(RDs_sum/k)

def calculate_LOF_for_TP(tp_lrd,LRDs,k):
  sum = 0.0

  for i in range(k):
    sum+=LRDs[i]

  average = sum/k
  return tp_lrd/average

def KNN(X_train, y_train, X_test, k):

  TestPoint_LRDs = np.array([], dtype=float)
  TestPoint_LOFs = np.array([], dtype=float)
  index = 0
  for i in range(len(X_test)):
    distances = []
    original_points = []

    for j in range(len(X_train)):

      dis = Euclidean_Distance(X_test[i], X_train[j])
      distances.append((dis, y_train[j]))  # Append as a tuple
      original_points.append((dis,X_train[j]))

    distances = tuple(sorted(distances))
    original_points = sorted(original_points, key=lambda x: x[0])
    # print(distances)
    distances = distances[0:k]
    original_points = original_points[0:k]
    # print("distances")
    # print(distances)
    # print("original points")
    # print(original_points)
    # print(original_points[0])
    # print(original_points[1])
    # print(original_points[2])

    knn_neighborhood = []
    reachability_distances = np.array([], dtype=float)
    LRDs = np.array([], dtype=float)
    # print(type(knn_neighborhood))
    for l in range(k):
      # print(l)
      knn_neighborhood.append((KNN_recursive(original_points[l],X_train,y_train, X_test,k)))
      # print("under knn recursive fun")
      # print(knn_neighborhood[l][0])
      # print(";;;;;;;;;;;")
      # print(distances[l][0])
      # print(";;;;;;;;;;;")
      max = calculate_RD(knn_neighborhood[l][0],distances[l][0])
      reachability_distances = np.append(reachability_distances,max)
      #print("appended for: ",l)
      # print("into lrd")
      lrd = calculate_LRD_for_neighbors(knn_neighborhood[l][0],reachability_distances[l],k)
      LRDs = np.append(LRDs,lrd)

    # print("knn neighborhood: ", knn_neighborhood)
    # print("RDs: ",reachability_distances)
    # print("lrds: ", LRDs)

    tp_lrd = calculate_LRD_for_TP(reachability_distances,k)
    TestPoint_LRDs = np.append(TestPoint_LRDs, tp_lrd)
    # print("LRD for T",TestPoint_LRDs[index])
    tp_lof = calculate_LOF_for_TP(TestPoint_LRDs[index],LRDs,k)
    TestPoint_LOFs = np.append(TestPoint_LOFs,tp_lof)
    # print("LOF for T",TestPoint_LOFs[index])
    index += 1

  print("\nTEST point LRDs\n")
  print(TestPoint_LRDs)

  print("\nTEST point LOFs\n")
  print(TestPoint_LOFs)

  return TestPoint_LOFs

k = 32
lof_values = KNN(X_train,y_train,X_test,k)

import matplotlib.pyplot as plt

# Create x-axis values (indices of test points)
x = np.arange(len(lof_values))

# Plot the LOF values as scatter points
plt.scatter(x, lof_values)

# Customize the plot
plt.title('LOF values for Test Points')
plt.xlabel('Test Point Index')
plt.ylabel('LOF Value')

# Show the plot
plt.show()

from sklearn.datasets import load_iris

# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Plot the Iris dataset
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', label='Iris')

# Plot the test points with LOF values as color
plt.scatter(X[:, 0][-len(lof_values):], X[:, 1][-len(lof_values):], color='red', label='Test LOF')

# Customize the plot
plt.title('Scatter Plot of Iris Dataset with Test LOF Values')
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.legend()

# Show the plot
plt.show()

from sklearn.datasets import load_iris
from sklearn.neighbors import LocalOutlierFactor

# Load the Iris dataset
dataset = load_iris()
X = dataset.data

# Create and fit the LOF model
lof = LocalOutlierFactor(n_neighbors= 132)  # Adjust n_neighbors as desired
outlier_scores = lof.fit_predict(X)

# Get the outlier scores and labels
outlier_scores = -lof.negative_outlier_factor_
outlier_labels = lof.fit_predict(X)

# Print the outlier scores and labels
for i, (score, label) in enumerate(zip(outlier_scores, outlier_labels)):
    print(f"Data point {i+1}: Outlier score = {score}, Label = {'Outlier' if label == -1 else 'Inlier'}")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.neighbors import LocalOutlierFactor

# Load the Iris dataset
dataset = load_iris()
X = dataset.data

# Create and fit the LOF model
lof = LocalOutlierFactor(n_neighbors=32)  # Adjust n_neighbors as desired
outlier_labels = lof.fit_predict(X)

# Extract outlier and inlier indices
outlier_indices = np.where(outlier_labels == -1)[0]
inlier_indices = np.where(outlier_labels == 1)[0]

# Plotting graph between PetalLengthCm & SepalLengthCm (Before)
sns.set_style("whitegrid")
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.scatter(X[:, 2], X[:, 0], c='blue', label='Inliers')
plt.xlabel('Petal Length (cm)')
plt.ylabel('Sepal Length (cm)')
plt.title('Before LOF')

# Plotting graph between PetalLengthCm & SepalLengthCm (After)
plt.subplot(1, 2, 2)
plt.scatter(X[inlier_indices, 2], X[inlier_indices, 0], c='blue', label='Inliers')
plt.scatter(X[outlier_indices, 2], X[outlier_indices, 0], c='red', label='Outliers')
plt.xlabel('Petal Length (cm)')
plt.ylabel('Sepal Length (cm)')
plt.title('After LOF')
plt.legend()

# Display the plot
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.neighbors import LocalOutlierFactor

# Load the Iris dataset
dataset = load_iris()
X = dataset.data

# Separate test points (first 30) and training points
X_test = X[:30]
X_train = X[30:]

# Create and fit the LOF model
lof = LocalOutlierFactor(n_neighbors=32)  # Adjust n_neighbors as desired
outlier_labels = lof.fit_predict(X_train)

# Extract outlier and inlier indices
outlier_indices = np.where(outlier_labels == -1)[0]
inlier_indices = np.where(outlier_labels == 1)[0]

# Plotting graph between PetalLengthCm & SepalLengthCm (Before)
sns.set_style("whitegrid")
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.scatter(X_train[:, 2], X_train[:, 0], c='blue', label='Inliers (Training)')
plt.scatter(X_test[:, 2], X_test[:, 0], c='green', label='Test')
plt.xlabel('Petal Length (cm)')
plt.ylabel('Sepal Length (cm)')
plt.title('Before LOF')

# Plotting graph between PetalLengthCm & SepalLengthCm (After)
plt.subplot(1, 2, 2)
plt.scatter(X_train[inlier_indices, 2], X_train[inlier_indices, 0], c='blue', label='Inliers')
plt.scatter(X_train[outlier_indices, 2], X_train[outlier_indices, 0], c='red', label='Outliers')
plt.scatter(X_test[:, 2], X_test[:, 0], c='green', label='Test')
plt.xlabel('Petal Length (cm)')
plt.ylabel('Sepal Length (cm)')
plt.title('After LOF')
plt.legend()

# Display the plot
plt.tight_layout()
plt.show()